{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import preprocess_captions\n",
    "import os.path\n",
    "from data import *\n",
    "\n",
    "if not os.path.exists(\"./data/captions.json\"):\n",
    "    preprocess_captions()\n",
    "\n",
    "batch_size = 2\n",
    "train_loader = get_loader(\"TRAIN\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1842\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size:\", len(train_loader.dataset.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Caption length')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Caption lengths distribution\n",
    "#\n",
    "\n",
    "lengths = {k: len(v) for k, v in train_loader.dataset.caption_lengths.items()}\n",
    "\n",
    "ax = sns.scatterplot(list(lengths.keys()), list(lengths.values()))\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.xlabel('Caption length', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length 28\n",
      "Min length 0\n"
     ]
    }
   ],
   "source": [
    "# TODO: figure out the images with 0 an 1-length caption\n",
    "\n",
    "print(\"Max length\", max(lengths))\n",
    "print(\"Min length\", min(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled indices: 87\n",
      "images.shape: torch.Size([2, 3, 224, 224])\n",
      "captions.shape: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Same-length indices sampler test\n",
    "#\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Randomly sample a caption length, and sample indices with that length.\n",
    "indices = train_loader.dataset.get_indices()\n",
    "print('Sampled indices: {}'.format(len(indices)))\n",
    "# Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "train_loader.batch_sampler.sampler = sampler\n",
    "\n",
    "# Obtain the batch.\n",
    "for batch in train_loader:\n",
    "    images, captions = batch[0], batch[1]\n",
    "    break\n",
    "    \n",
    "print('images.shape:', images.shape)\n",
    "print('captions.shape:', captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256])\n",
      "torch.Size([2, 5, 1842])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Encoder and Decoder forward pass test\n",
    "#\n",
    "\n",
    "from models import Encoder, Decoder\n",
    "\n",
    "embed_size = 256\n",
    "encoder = Encoder(embed_size)\n",
    "\n",
    "hidden_size = 512\n",
    "vocab_size = len(train_loader.dataset.vocab)\n",
    "decoder = Decoder(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "if batch_size == 1:\n",
    "    encoder.eval() # To not use batch norm when I'm testing with batch size=1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    images = images.cuda()\n",
    "    captions = captions.cuda()\n",
    "    \n",
    "features = encoder(images)\n",
    "outputs = decoder(features, captions)\n",
    "\n",
    "# Features shape should be (batch_size, embed_size)\n",
    "print(features.shape)\n",
    "\n",
    "# Outputs shape should be (batch_size, captions.shape[1], vocab_size)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Encoder and Decoder backward pass test\n",
    "#\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "params = (list(filter(lambda p: p.requires_grad, encoder.parameters()))+\n",
    "        list(filter(lambda p: p.requires_grad, decoder.parameters())))\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "loss = criterion(outputs.view(-1, len(train_loader.dataset.vocab)), captions.view(-1))\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 256])\n",
      "torch.Size([5, 6, 1842])\n",
      "torch.Size([5, 5, 28])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Validation loader test\n",
    "#\n",
    "\n",
    "from train_utils import bleu_eval, early_stopping\n",
    "\n",
    "val_loader = get_loader(\"VAL\", 5)\n",
    "\n",
    "# Obtain batch\n",
    "for batch in val_loader:\n",
    "    images, captions, all_caps = batch[0], batch[1], batch[2]\n",
    "    break\n",
    "    \n",
    "embed_size = 256\n",
    "encoder = Encoder(embed_size)\n",
    "\n",
    "hidden_size = 512\n",
    "vocab_size = len(train_loader.dataset.vocab)\n",
    "decoder = Decoder(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "encoder.eval() # To not use batch norm when I'm testing with batch size=1\n",
    "decoder.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    images = images.cuda()\n",
    "    captions = captions.cuda()\n",
    "    \n",
    "features = encoder(images)\n",
    "outputs = decoder(features, captions)\n",
    "\n",
    "# features shape should be (batch_size, embed_size)\n",
    "print(features.shape)\n",
    "\n",
    "# outputs shape should be (batch_size, captions.shape[1], vocab_size)\n",
    "print(outputs.shape)\n",
    "\n",
    "# all_caps shape should be (batch_size, #caption per image, max_caption_length)\n",
    "print(all_caps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Batched BLEU scoring test\n",
    "#\n",
    "\n",
    "_, predicted = outputs.max(2)\n",
    "candidates = predicted.to(\"cpu\").numpy()\n",
    "batch_bleu_score = bleu_eval(candidates, all_caps, val_loader.dataset.vocab)\n",
    "batch_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Early stopping test\n",
    "#\n",
    "\n",
    "a = [1, 1, 1, 5, 1, 1, 1]\n",
    "print(early_stopping(a))\n",
    "a = [1, 1, 1, 5, 6, 1, 1]\n",
    "print(early_stopping(a))\n",
    "a = [1, 1, 1, 5, 5, 5, 5]\n",
    "print(early_stopping(a))\n",
    "a = [1, 2, 3, 4, 5, 6, 7]\n",
    "print(early_stopping(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/models/checkpoints/tmp-model-1-1.ckpt\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Saving checkpoint test\n",
    "#\n",
    "import os\n",
    "epoch = 1\n",
    "i = 1\n",
    "filename = os.path.join(\"./data/models/checkpoints/tmp-model-{}-{}.ckpt\".format(epoch, i))\n",
    "print(filename)\n",
    "torch.save({\"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict(),\n",
    "            \"optimizer\" : optimizer.state_dict(),\n",
    "            \"total_loss\": 0,\n",
    "            \"epoch\": epoch,\n",
    "            \"train_step\": i,\n",
    "        }, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
