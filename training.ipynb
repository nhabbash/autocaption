{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, sampler\n",
    "from models import Encoder, Decoder\n",
    "from train_utils import train, validate, early_stopping\n",
    "from data import Vocabulary, get_loader\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to run `wandb login` in the terminal to authenticate, for some reason `!wandb login` doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "cfg = { \n",
    "        \"device\" : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"batch_size\" : 32,\n",
    "        \"num_epochs\" : 50,\n",
    "        \"lr\" : 0.001,\n",
    "        \"momentum\": 0.01,\n",
    "        \"hidden_size\": 512,\n",
    "        \"embed_size\": 512,\n",
    "        \"n_layers\": 1,\n",
    "        \"dropout\": 0.1,\n",
    "        \"seed\" : 0,\n",
    "        \"dataset\": \"flickr8k\"\n",
    "        }\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(cfg[\"seed\"])\n",
    "np.random.seed(cfg[\"seed\"])\n",
    "#torch.backends.cudnn.deterministic = True # It makes training slower\n",
    "\n",
    "# Logs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_bleus = []\n",
    "best_bleu = float(\"-INF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = get_loader(\"TRAIN\", cfg[\"batch_size\"])\n",
    "val_loader = get_loader(\"VAL\", cfg[\"batch_size\"])\n",
    "\n",
    "# Models\n",
    "encoder = Encoder(cfg[\"embed_size\"], cfg[\"momentum\"]).to(cfg[\"device\"])\n",
    "decoder = Decoder(cfg[\"embed_size\"], \n",
    "                  cfg[\"hidden_size\"], \n",
    "                  len(train_loader.dataset.vocab),\n",
    "                  cfg[\"n_layers\"],\n",
    "                  cfg[\"dropout\"]).to(cfg[\"device\"])\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(cfg[\"device\"])\n",
    "params = (list(filter(lambda p: p.requires_grad, encoder.parameters()))+\n",
    "        list(filter(lambda p: p.requires_grad, decoder.parameters())))\n",
    "optimizer = torch.optim.Adam(params, lr=cfg[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/dodicin/autocaption\" target=\"_blank\">https://app.wandb.ai/dodicin/autocaption</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/dodicin/autocaption/runs/22ug88tz\" target=\"_blank\">https://app.wandb.ai/dodicin/autocaption/runs/22ug88tz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x1ed7c33eb88>,\n",
       " <wandb.wandb_torch.TorchGraph at 0x1ed7c339c88>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wandb project init\n",
    "wandb.init(\n",
    "  project=\"autocaption\",\n",
    "  notes=\"baseline\",\n",
    "  tags=[\"baseline\"],\n",
    "  config=cfg,\n",
    ")\n",
    "\n",
    "wandb.watch([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.00% [6/50 49:46<6:05:04]\n",
       "    </div>\n",
       "    \n",
       "> Epoch 1/50<p># TRAIN<p># Loss 3.277, Perplexity 26.495<p># VALIDATION<p># Loss 2.996, Perplexity 19.999, BLEU 0.048<p>>Runtime 492.689<p>Validation BLEU improved from -inf to 0.04802467531604206, saving model at ./data/models/best-model.ckpt<p>> Epoch 2/50<p># TRAIN<p># Loss 2.575, Perplexity 13.136<p># VALIDATION<p># Loss 2.901, Perplexity 18.192, BLEU 0.054<p>>Runtime 483.696<p>Validation BLEU improved from 0.04802467531604206 to 0.054435966910661764, saving model at ./data/models/best-model.ckpt<p>> Epoch 3/50<p># TRAIN<p># Loss 2.289, Perplexity 9.869<p># VALIDATION<p># Loss 2.856, Perplexity 17.387, BLEU 0.054<p>>Runtime 483.366<p>Validation BLEU did not improve, saving model at ./data/models/model-2.ckpt<p>> Epoch 4/50<p># TRAIN<p># Loss 2.093, Perplexity 8.108<p># VALIDATION<p># Loss 2.888, Perplexity 17.954, BLEU 0.052<p>>Runtime 484.959<p>Validation BLEU did not improve, saving model at ./data/models/model-3.ckpt<p>> Epoch 5/50<p># TRAIN<p># Loss 1.912, Perplexity 6.768<p># VALIDATION<p># Loss 2.904, Perplexity 18.246, BLEU 0.050<p>>Runtime 514.665<p>Validation BLEU did not improve, saving model at ./data/models/model-4.ckpt<p>> Epoch 6/50<p># TRAIN<p># Loss 1.754, Perplexity 5.776<p># VALIDATION<p># Loss 2.938, Perplexity 18.876, BLEU 0.053<p>>Runtime 525.690<p>Validation BLEU did not improve, saving model at ./data/models/model-5.ckpt<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='157' class='' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [157/157 01:17<00:00 Epoch 7, Loss 2.842, Perplexity 17.149, BLEU 0.011]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mb = master_bar(range(cfg[\"num_epochs\"]))\n",
    "\n",
    "for epoch in mb:\n",
    "    start = time.time()\n",
    "    train_loss = train( loader=train_loader,\n",
    "                        encoder=encoder,\n",
    "                        decoder=decoder,\n",
    "                        criterion=criterion,\n",
    "                        opt=optimizer,\n",
    "                        epoch=epoch,\n",
    "                        cfg=cfg,\n",
    "                        mb=mb)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    val_loss, val_bleu = validate(  loader=val_loader,\n",
    "                                    encoder=encoder,\n",
    "                                    decoder=decoder,\n",
    "                                    criterion=criterion,\n",
    "                                    epoch=epoch,\n",
    "                                    cfg=cfg,\n",
    "                                    mb=mb)\n",
    "    val_losses.append(val_loss)\n",
    "    val_bleus.append(val_bleu)\n",
    "    \n",
    "    mb.write('> Epoch {}/{}'.format(epoch + 1, cfg[\"num_epochs\"]))\n",
    "    mb.write('# TRAIN')\n",
    "    mb.write('# Loss {:.3f}, Perplexity {:.3f}'.format(train_loss, np.exp(train_loss)))\n",
    "    mb.write('# VALIDATION')\n",
    "    mb.write('# Loss {:.3f}, Perplexity {:.3f}, BLEU {:.3f}'.format(val_loss, np.exp(val_loss), val_bleu))\n",
    "    mb.write(\">Runtime {:.3f}\".format(time.time() - start))\n",
    "\n",
    "    # Send logs to wandb\n",
    "    wandb.log({'train_loss': train_loss,\n",
    "               'train_perplexity': np.exp(train_loss),\n",
    "               'val_loss': val_loss,\n",
    "               'val_perplexity': np.exp(val_loss),\n",
    "               'val_bleu': val_bleu}, step=epoch)\n",
    "    \n",
    "    if val_bleu > best_bleu:\n",
    "        mb.write(\"Validation BLEU improved from {} to {}, saving model at ./data/models/best-model.ckpt\".format(best_bleu, val_bleu))\n",
    "        best_bleu = val_bleu\n",
    "        \n",
    "        filename = os.path.join(\"./data/models\", \"best-model.ckpt\")\n",
    "        torch.save({\"encoder\": encoder.state_dict(),\n",
    "                    \"decoder\": decoder.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"train_losses\": train_losses,\n",
    "                    \"val_losses\": val_losses,\n",
    "                    \"best_bleu\": best_bleu,\n",
    "                    \"val_bleus\": val_bleus,\n",
    "                    \"epoch\": epoch\n",
    "                }, filename)\n",
    "    else:\n",
    "        mb.write(\"Validation BLEU did not improve, saving model at ./data/models/model-{}.ckpt\".format(epoch))\n",
    "        filename = os.path.join(\"./data/models\", \"model-{}.ckpt\".format(epoch))\n",
    "        torch.save({\"encoder\": encoder.state_dict(),\n",
    "                    \"decoder\": decoder.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"train_losses\": train_losses,\n",
    "                    \"val_losses\": val_losses,\n",
    "                    \"best_bleu\": best_bleu,\n",
    "                    \"val_bleus\": val_bleus,\n",
    "                    \"epoch\": epoch\n",
    "                }, filename)\n",
    "    \n",
    "    # Saving last model to wandb, works only if Jupyter is executed as Admin\n",
    "    try: \n",
    "        wandb.save(filename)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    if epoch > 5:\n",
    "        if early_stopping(val_bleus, patience=3):\n",
    "            mb.write(\"Validation BLEU did not improve for 3 consecutive epochs, stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embed): Embedding(1842, 512)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lstm): LSTM(512, 512, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=1842, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from models import Encoder, Decoder\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_caption\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "loader = get_loader(\"TEST\", cfg[\"batch_size\"])\n",
    "\n",
    "model_name = 'best-model.ckpt'\n",
    "checkpoint = torch.load(os.path.join('./data/models', model_name))\n",
    "encoder = Encoder(cfg[\"embed_size\"], cfg[\"momentum\"]).to(cfg[\"device\"])\n",
    "decoder = Decoder(cfg[\"embed_size\"], \n",
    "                  cfg[\"hidden_size\"], \n",
    "                  len(train_loader.dataset.vocab),\n",
    "                  cfg[\"n_layers\"],\n",
    "                  cfg[\"dropout\"]).to(cfg[\"device\"])\n",
    "\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='999' class='' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [999/999 05:45<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "results_beam = []\n",
    "\n",
    "mb = progress_bar(loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (orig_image, image, all_caps) in mb:\n",
    "        image = image.to(cfg[\"device\"])\n",
    "            \n",
    "        # Greedy\n",
    "        candidates = get_caption(image, \n",
    "                                encoder, \n",
    "                                decoder, \n",
    "                                loader.dataset.vocab,\n",
    "                                \"greedy\",\n",
    "                                True)\n",
    "\n",
    "        candidates = [c.split() for c in candidates][0]\n",
    "        all_caps = [c[0].split() for c in all_caps]\n",
    "        \n",
    "        bleu_score = sentence_bleu(all_caps, candidates, smoothing_function=SmoothingFunction().method1)\n",
    "        \n",
    "        candidates = [\" \".join(candidates) for c in candidates]\n",
    "        all_caps = [\" \".join(c) for c in all_caps]\n",
    "        \n",
    "        results.append({\"orig_image\": orig_image, \n",
    "                        \"caption\": candidates,\n",
    "                        \"all_caps\": all_caps,\n",
    "                        \"bleu\": bleu_score})\n",
    "        \n",
    "        # Beam\n",
    "        candidates = get_caption(image, \n",
    "                                encoder, \n",
    "                                decoder, \n",
    "                                loader.dataset.vocab,\n",
    "                                \"beam\",\n",
    "                                True)\n",
    "\n",
    "        candidates_bleu = [c.split() for c in candidates][0]\n",
    "        candidates_bleu = [candidates_bleu[0]]\n",
    "        all_caps = [c[0].split() for c in all_caps]\n",
    "        \n",
    "        bleu_score = sentence_bleu(all_caps, candidates_bleu, smoothing_function=SmoothingFunction().method1)\n",
    "        \n",
    "        all_caps = [\" \".join(c) for c in all_caps]\n",
    "        \n",
    "        results_beam.append({\"orig_image\": orig_image, \n",
    "                        \"caption\": candidates,\n",
    "                        \"all_caps\": all_caps,\n",
    "                        \"bleu\": bleu_score})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda k: k['bleu'], reverse=True) \n",
    "\n",
    "top = results[0:5]\n",
    "worst = results[-5:]\n",
    "\n",
    "for e in top:\n",
    "    orig_image = e[\"orig_image\"]\n",
    "    caption = e[\"caption\"]\n",
    "    all_caps = e[\"all_caps\"]\n",
    "    bleu = e[\"bleu\"]\n",
    "\n",
    "    plt.imshow(np.squeeze(orig_image))\n",
    "    #plt.title(\"Sampled Image\")\n",
    "    #plt.figtext(0.5, 0.01, caption, wrap=True, ha='center', fontsize=12)\n",
    "    #plt.figtext(0.5, -0.05, \"BLEU4 score: {:.2f}\".format(bleu), wrap=True, ha='center', fontsize=12)\n",
    "    plt.show()\n",
    "    print(\">Generated caption: \")\n",
    "    print(caption)\n",
    "    print(\">Original captions: \")\n",
    "    for c in all_caps:\n",
    "        print(c)\n",
    "    print(\">BLEU4 score: {:.3f}\".format(bleu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for e in worst:\n",
    "    orig_image = e[\"orig_image\"]\n",
    "    caption = e[\"caption\"]\n",
    "    all_caps = e[\"all_caps\"]\n",
    "    bleu = e[\"bleu\"]\n",
    "\n",
    "    plt.imshow(np.squeeze(orig_image))\n",
    "    #plt.title(\"Sampled Image\")\n",
    "    #plt.figtext(0.5, 0.01, caption, wrap=True, ha='center', fontsize=12)\n",
    "    #plt.figtext(0.5, -0.05, \"BLEU4 score: {:.2f}\".format(bleu), wrap=True, ha='center', fontsize=12)\n",
    "    plt.show()\n",
    "    print(\">Generated caption: \")\n",
    "    print(caption)\n",
    "    print(\">Original captions: \")\n",
    "    for c in all_caps:\n",
    "        print(c)\n",
    "    print(\">BLEU4 score: {:.3f}\".format(bleu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_beam = sorted(results_beam, key=lambda k: k['bleu'], reverse=True) \n",
    "\n",
    "top = results_beam[0:5]\n",
    "worst = results_beam[-5:]\n",
    "\n",
    "for e in top:\n",
    "    orig_image = e[\"orig_image\"]\n",
    "    caption = e[\"caption\"]\n",
    "    all_caps = e[\"all_caps\"]\n",
    "    bleu = e[\"bleu\"]\n",
    "\n",
    "    plt.imshow(np.squeeze(orig_image))\n",
    "    #plt.title(\"Sampled Image\")\n",
    "    #plt.figtext(0.5, 0.01, caption, wrap=True, ha='center', fontsize=12)\n",
    "    #plt.figtext(0.5, -0.05, \"BLEU4 score: {:.2f}\".format(bleu), wrap=True, ha='center', fontsize=12)\n",
    "    plt.show()\n",
    "    print(\">Generated caption: \")\n",
    "    print(caption)\n",
    "    print(\">Original captions: \")\n",
    "    for c in all_caps:\n",
    "        print(c)\n",
    "    print(\">BLEU4 score: {:.3f}\".format(bleu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in worst:\n",
    "    orig_image = e[\"orig_image\"]\n",
    "    caption = e[\"caption\"]\n",
    "    all_caps = e[\"all_caps\"]\n",
    "    bleu = e[\"bleu\"]\n",
    "\n",
    "    plt.imshow(np.squeeze(orig_image))\n",
    "    #plt.title(\"Sampled Image\")\n",
    "    #plt.figtext(0.5, 0.01, caption, wrap=True, ha='center', fontsize=12)\n",
    "    #plt.figtext(0.5, -0.05, \"BLEU4 score: {:.2f}\".format(bleu), wrap=True, ha='center', fontsize=12)\n",
    "    plt.show()\n",
    "    print(\">Generated caption: \")\n",
    "    print(caption)\n",
    "    print(\">Original captions: \")\n",
    "    for c in all_caps:\n",
    "        print(c)\n",
    "    print(\">BLEU4 score: {:.3f}\".format(bleu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "greedy_test_bleu = [d['bleu'] for d in results]\n",
    "beam_test_bleu = [d['bleu'] for d in results_beam]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.distplot(greedy_test_bleu, label=\"Greedy search\")\n",
    "sns.distplot(beam_test_bleu, label=\"Beam search\")\n",
    "plt.legend(fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "data = asarray([greedy_test_bleu, beam_test_bleu])\n",
    "savetxt('data/results/greedy_beam_20_04.csv', data, delimiter=',')\n",
    "\n",
    "wandb.run.summary[\"greedy_test_bleu\"] = greedy_test_bleu\n",
    "wandb.run.summary[\"beam_test_bleu\"] = beam_test_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "data = loadtxt('data/results/greedy_beam_19_04.csv', delimiter=',')\n",
    "greedy_test_bleu = data[0]\n",
    "beam_test_bleu = data[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
